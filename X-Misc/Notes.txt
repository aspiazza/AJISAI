# AJISAI NOTES

print out requirements.txt:
pipreqs AJISAI-Project\Web-App\

- Guides
    + Fast-API Templates:
        > https://www.youtube.com/watch?v=JC5q22g3yQM

    + ML Model on Fast-API
        > https://www.youtube.com/watch?v=Mw9etoRz0Ic

    + Docker and Fast-API
        > https://fastapi.tiangolo.com/deployment/docker/
        > https://towardsdatascience.com/tensorflow-model-deployment-using-fastapi-docker-4b398251af75
        > https://medium.com/swlh/python-with-docker-fastapi-c4c304c7a93b
        > https://www.youtube.com/watch?v=2a5414BsYqw

    + ML Web App with Flask
        > https://towardsdatascience.com/image-classification-of-pcbs-and-its-web-application-flask-c2b26039924a

    + Graphs
        > https://towardsdatascience.com/how-did-i-classify-50-chart-types-by-purpose-a6b0aa5b812d

    + Generators
        > https://towardsdatascience.com/how-to-use-yield-in-python-5f1fbb864f94

    + Kaggle Competition
        > https://towardsdatascience.com/my-first-gold-in-kaggle-tips-and-tricks-for-an-nlp-competition-cec48dda5895
        > https://towardsdatascience.com/18-common-python-anti-patterns-i-wish-i-had-known-before-44d983805f0f
        > https://towardsdatascience.com/stop-using-pandas-get-dummies-for-feature-encoding-5d2cd07cb4fc

    + Optuna
        > https://optuna.readthedocs.io/en/v1.3.0/reference/samplers.html
        > https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html
        > https://machinelearningapplied.com/hyperparameter-search-with-optuna-part-3-keras-cnn-classification-and-ensembling/
        > https://optuna.org/#code_examples


Code:

. MinMaxScaler (sklearn.preprocessing) = Normalizing binary data to 1 or 0
. OnehotEncoder (sklearn.preprocessing) = One hot encode categorical data
. random.sample(glob.blob('cat*'), 100) = Grabs 100 files containing word cat
. shutil.move(source, dest) = Moves files
. random.choice(os.listdir('example/directory')) = choose random file/image
. StratifiedShuffleSplit(n_splts=, test_size=) = When you want your data stratified
. SimpleImputer(strategy= "median") = Handling missing data


.vectorizer = CountVectorizer()
 vectorizer.fit_transform(train_x)
 vectorizer.transform(test_x)       #To vectorized words


# print(self.test_gen.classes)
# print(self.test_gen.class_indices)
# test_images, test_labels = next(self.test_gen)



HTML Site:
Bright Green: rgb(5, 182, 105)
Dark Green: rgb(19, 66, 19)
Black: rgb(0, 0, 0)


# Plotting average image

import os
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image

# making n X m matrix
def img2np(path, list_of_filename, size = (64, 64)):
    # iterating through each file
    for fn in list_of_filename:
        fp = path + fn
        current_image = image.load_img(fp, target_size = size,
                                       color_mode = 'grayscale')
        # covert image to a matrix
        img_ts = image.img_to_array(current_image)
        # turn that into a vector / 1D array
        img_ts = [img_ts.ravel()]
        try:
            # concatenate different images
            full_mat = np.concatenate((full_mat, img_ts))
        except UnboundLocalError:
            # if not assigned yet, assign one
            full_mat = img_ts
    return full_mat

# run it on our folders
normal_images = img2np(f'{train_dir}/NORMAL/', normal_imgs)
pnemonia_images = img2np(f'{train_dir}/PNEUMONIA/', pneumo_imgs)

def find_mean_img(full_mat, title, size = (64, 64)):
    # calculate the average
    mean_img = np.mean(full_mat, axis = 0)
    # reshape it back to a matrix
    mean_img = mean_img.reshape(size)
    plt.imshow(mean_img, vmin=0, vmax=255, cmap='Greys_r')
    plt.title(f'Average {title}')
    plt.axis('off')
    plt.show()
    return mean_img

norm_mean = find_mean_img(normal_images, 'NORMAL')
pneu_mean = find_mean_img(pnemonia_images, 'PNEUMONIA')
